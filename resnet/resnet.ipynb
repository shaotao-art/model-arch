{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"./resnet.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inchannels, outchannels, kernel_size, stride, padding) -> None:\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(inchannels, outchannels, kernel_size, stride, padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm2d(outchannels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"./residual_connection.png\" height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "there are two type of residual connection:\n",
    "1. if two has same channel, do elementwise add\n",
    "2. otherwise, first do conv1x1 to obtain same channel, then do elementwise add\n",
    "\n",
    "in each ResLayer (three convs as a block, block * repeat time as a layer)\n",
    "1. in first block's conv3x3, we need do downsampling\n",
    "2. in first block, we need do conv1x1 to obtain the same channel, mind that the img_size is also different\n",
    "3. in later block, we can do elementwise add\n",
    "\n",
    "TIPS:\n",
    "in Conv2_X:\n",
    "its conv3x3 do not need do downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, config, conv2_flag) -> None:\n",
    "        super().__init__()\n",
    "        self.conv2_flag = conv2_flag\n",
    "        self.repeat_time = config[4]\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "        self.first_conv1 =ConvBlock(self.config[0], self.config[1], (1,1), 1, (0,0))\n",
    "        self.later_conv1 =ConvBlock(self.config[3], self.config[1], (1,1), 1, (0,0))\n",
    "\n",
    "        # conv2_X's 3x3 does not need do downsampling\n",
    "        # but in later conv3/4/5_X\n",
    "        # one of the conv3x3s will have stride == 2 to do downsampling\n",
    "        # conv2_flag to identify conv2_X\n",
    "        if self.conv2_flag == False:\n",
    "            self.conv2_downsample = ConvBlock(self.config[1], self.config[2], (3,3), 2, (1,1))\n",
    "        self.conv2 = ConvBlock(self.config[1], self.config[2], (3,3), 1,(1,1))\n",
    "\n",
    "        self.conv3 = ConvBlock(self.config[2], self.config[3], (1,1), 1, (0,0))\n",
    "\n",
    "\n",
    "    # Conv3/4/5_X's first block\n",
    "    def _first_subblock(self, x, inchannel, outchannel):\n",
    "        _ = self.first_conv1(x)\n",
    "        # do downsampling\n",
    "        _ = self.conv2_downsample(_)\n",
    "        _ = self.conv3(_)\n",
    "        # do conv and then element wise add\n",
    "        # mind this conv do downsampling\n",
    "        conv = ConvBlock(inchannel, outchannel, (4,4), 2, (1,1))\n",
    "        return _ + conv(x)\n",
    "        \n",
    "    # Conv2/3/4/5_X's later block\n",
    "    def _later_subblock(self, x):\n",
    "        _ = self.later_conv1(x)\n",
    "        _ = self.conv2(_)\n",
    "        _ = self.conv3(_)\n",
    "        return _ + x           \n",
    "\n",
    "    # Conv2_X's first block\n",
    "    def _conv2_first_subblock(self, x, inchannel, outchannel):\n",
    "        _ = self.first_conv1(x)\n",
    "        _ = self.conv2(_)\n",
    "        _ = self.conv3(_)\n",
    "        # this conv do not do downsampling\n",
    "        conv = ConvBlock(inchannel, outchannel, (1,1), 1, (0,0))\n",
    "        return _ + conv(x)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv3/4/5_X\n",
    "        if self.conv2_flag ==False:\n",
    "            x = self._first_subblock(x, self.config[0], self.config[3])\n",
    "            for _ in range(self.repeat_time - 1):\n",
    "                x = self._later_subblock(x)\n",
    "            return x\n",
    "        # Conv2_X\n",
    "        x = self._conv2_first_subblock(x, self.config[0], self.config[3])\n",
    "        for _ in range(self.repeat_time - 1):\n",
    "            x = self._later_subblock(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, inchannel, num_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.config = {\n",
    "        # in_channel conv1channel conv2channel conv3channel repeat_time\n",
    "        # below: arch of res50\n",
    "            'conv2_x': [64, 64, 64, 256, 3],\n",
    "            'conv3_x': [256, 128, 128, 512, 4],\n",
    "            'conv4_x': [512, 256, 256, 1024, 6],\n",
    "            'conv5_x': [1024, 512, 512, 2048, 3]\n",
    "                }                \n",
    "        self.conv1 = nn.Conv2d(inchannel, 64, (7,7), 2, (3,3))\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.max_pool = nn.MaxPool2d((3,3), 2, (1,1))\n",
    "        \n",
    "        self.Conv2_X = ResBlock(self.config[\"conv2_x\"], True)\n",
    "        self.Conv3_X = ResBlock(self.config[\"conv3_x\"], False)\n",
    "        self.Conv4_X = ResBlock(self.config[\"conv4_x\"], False)\n",
    "        self.Conv5_X = ResBlock(self.config[\"conv5_x\"], False)\n",
    "        self.avg_pool = nn.AvgPool2d((7,7), 1, (0,0))\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # (N, img_channel, 224, 224)\n",
    "        x = self.max_pool(self.bn(self.conv1(x)))\n",
    "        # (N, 64, 56, 56)\n",
    "        x = self.Conv2_X(x)\n",
    "        # (N, 256, 56, 56)\n",
    "        x = self.Conv3_X(x)\n",
    "        # (N, 512, 28, 28)\n",
    "        x = self.Conv4_X(x)\n",
    "        # (N, 1024, 14, 14)\n",
    "        x = self.Conv5_X(x)\n",
    "        # (N, 2048, 7, 7)\n",
    "        x = self.avg_pool(x)\n",
    "        # (N, 2048, 1, 1)\n",
    "        x = x.reshape((x.shape[0],-1))\n",
    "        # (N, 2048)\n",
    "        x = self.fcs(x)\n",
    "        # (N, num_class)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(3, 1000)\n",
    "x = torch.rand((16, 3, 224, 224))\n",
    "print(net(x).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b29e1734725db1faeb4b8d5e1c0f2aeef17f9af1ed7138203a137e006bcde4ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
